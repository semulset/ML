{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca972ae",
   "metadata": {},
   "source": [
    "사이킷런 LinearRegression 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8ae96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6607e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 2*np.random.rand(100, 1)\n",
    "y = 4+3*X + np.random.rand(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a97e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = np.array([[0], [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743f4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.square(lin_reg.predict(X)-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c92c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c198b2",
   "metadata": {},
   "source": [
    "**확률적 경사하강법(SGDRegressor) 사이킷런 함수 매개변수**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce60fc8",
   "metadata": {},
   "source": [
    "**loss:**\n",
    "의미: 손실 함수(loss function)를 지정합니다. 이 함수는 모델이 예측한 값과 실제 타겟 값 사이의 오차를 계산하는데 사용됩니다. 회귀 모델에서는 주로 최소제곱 오차('squared_loss')를 사용합니다.\n",
    "기본값: 'squared_loss'\n",
    "\n",
    "**penalty:**\n",
    "의미: 규제(regularization) 항을 지정합니다. 규제는 모델의 복잡도를 조절하여 과적합(overfitting)을 방지합니다. L1 규제('l1'), L2 규제('l2'), ElasticNet 규제('elasticnet') 등이 가능합니다.\n",
    "기본값: None (규제를 적용하지 않음)\n",
    "\n",
    "**alpha:**\n",
    "의미: 규제의 강도를 조절하는 하이퍼파라미터입니다. 값이 클수록 강한 규제가 적용됩니다.\n",
    "기본값: 0.0001\n",
    "\n",
    "**learning_rate:**\n",
    "의미: 학습 속도를 결정하는 파라미터입니다. 'constant', 'optimal', 'invscaling', 'adaptive' 등의 값을 선택할 수 있으며, 각각에 따라 학습 속도 조정 방법이 달라집니다.\n",
    "기본값: 'optimal'\n",
    "\n",
    "**eta0:**\n",
    "의미: 학습 속도의 초기값을 설정하는 파라미터입니다. 학습 속도가 'constant'인 경우 사용됩니다.\n",
    "기본값: 0.01\n",
    "\n",
    "**max_iter:**\n",
    "의미: 최대 반복 횟수를 지정합니다. 학습을 위해 데이터를 몇 번 반복해서 사용할지를 결정합니다.\n",
    "기본값: 1000\n",
    "\n",
    "**random_state:**\n",
    "의미: 난수 생성 시드를 지정합니다. 이를 통해 학습 시의 난수를 재현 가능하게 합니다.\n",
    "기본값: None\n",
    "\n",
    "**epsilon:**\n",
    "의미: epsilon 값은 Huber 손실 함수(Huber loss function)를 사용할 때 임계값(threshold)으로 사용됩니다. Huber 손실은 최소제곱 오차와 절댓값 손실(MAE)을 혼합한 손실 함수로, 이상치(outlier)에 더 강건한 모델을 만들기 위해 사용됩니다.\n",
    "기본값: 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(max_iter=50, penalty=None, eta0 = 0.1, random_state=42)\n",
    "sgd_reg.fit(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7110de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa6ba4",
   "metadata": {},
   "source": [
    "**다항 회귀**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)\n",
    "print(poly_features.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9310f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d610c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3af724",
   "metadata": {},
   "source": [
    "확장된 데이터(X_poly)에 LinearRegression 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587cf855",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly, y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5195a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.score(X_poly, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c535d",
   "metadata": {},
   "source": [
    "**규제 모델**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a73498",
   "metadata": {},
   "source": [
    "과대적합을 감소시키는 방법\n",
    "- 비용 함수에 alpha 값으로 패널티를 부여해 회귀 계수(θ)의 크기를 감소시켜 과적합 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2af3e8",
   "metadata": {},
   "source": [
    "릿지(Ridge) : L2 규제 적용, 모든 특성들이 약간의 가중치를 갖도록 함 <br>\n",
    "라쏘(Lasso) : L1 규제 적용, 중요하지 않은 특성들의 가중치를 0으로 수렴 <br>\n",
    "엘라스틱넷(ElasticNet) : L2,  L1 규제를 결합한 모델\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce43195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(penalty='l1', random_state=42)\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "sgd_reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe087c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg = Lasso(alpha=0.0001, random_state=42)\n",
    "lasso_reg.fit(X,y.ravel())\n",
    "lasso_reg.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52140adc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
